{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import models\n",
    "from torchvision.transforms import *\n",
    "\n",
    "from datasets import *\n",
    "from transforms import *\n",
    "\n",
    "from utils import rlenc, rlenc_np, FasterRle, gzip_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_img_size = 101\n",
    "img_size = 128\n",
    "padding = compute_padding(orig_img_size, orig_img_size, img_size)\n",
    "d_y0, d_y1, d_x0, d_x1 = padding\n",
    "y0, y1, x0, x1 = d_y0, d_y0 + orig_img_size, d_x0, d_x0 + orig_img_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y0, y1, x0, x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(args, model, batch, flipped_batch, use_gpu):\n",
    "    \n",
    "    image_ids, inputs = batch['image_id'], batch['input']\n",
    "    if use_gpu:\n",
    "        inputs = inputs.cuda()\n",
    "        \n",
    "    # predict original data\n",
    "    outputs, _, _ = model(inputs)\n",
    "    probs = torch.sigmoid(outputs)\n",
    "\n",
    "    if flipped_batch is not None:\n",
    "        flipped_image_ids, flipped_inputs = flipped_batch['image_id'], flipped_batch['input']\n",
    "        # assert image_ids == flipped_image_ids\n",
    "        if use_gpu:\n",
    "            flipped_inputs = flipped_inputs.cuda()\n",
    "            \n",
    "        # predict flipped data\n",
    "        flipped_outputs, _, _ = model(flipped_inputs)\n",
    "        flipped_probs = torch.sigmoid(flipped_outputs)\n",
    "\n",
    "        probs += torch.flip(flipped_probs, (3,))  # flip back and add\n",
    "        probs *= 0.5\n",
    "\n",
    "    probs = probs.squeeze(1).cpu().numpy()    # squeeze channel dimension\n",
    "    if args.resize:\n",
    "        probs = np.swapaxes(probs, 0, 2)\n",
    "        # using opencv-python\n",
    "        import cv2\n",
    "        probs = cv2.resize(probs, (orig_img_size, orig_img_size), interpolation=cv2.INTER_LINEAR)\n",
    "#         from skimage.transform import resize\n",
    "#         probs = resize(probs, (orig_img_size, orig_img_size) )\n",
    "        probs = np.swapaxes(probs, 0, 2)\n",
    "    else:\n",
    "        probs = probs[:, y0:y1, x0:x1]\n",
    "\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(args):\n",
    "    # test dataset\n",
    "    test_transform = Compose([PrepareImageAndMask(),\n",
    "                              ResizeToNxN(img_size) if args.resize else PadToNxN(img_size), HWCtoCHW()])\n",
    "    test_dataset = SaltIdentification(mode='test', transform=test_transform, preload=False)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=args.batch_size, num_workers=args.dataload_workers_nums)\n",
    "\n",
    "    # flipped test dataset\n",
    "    flipped_test_transform = Compose([PrepareImageAndMask(), HorizontalFlip(),\n",
    "                                      ResizeToNxN(img_size) if args.resize else PadToNxN(img_size), HWCtoCHW()])\n",
    "    flipped_test_dataset = SaltIdentification(mode='test', transform=flipped_test_transform, preload=False)\n",
    "    flipped_test_dataloader_iter = iter(DataLoader(flipped_test_dataset, batch_size=args.batch_size,\n",
    "                                                   num_workers=args.dataload_workers_nums))\n",
    "\n",
    "    model.eval()\n",
    "    torch.set_grad_enabled(False)\n",
    "\n",
    "    prediction = {}\n",
    "    submission = {}\n",
    "    #pbar = tqdm(test_dataloader, unit=\"images\", unit_scale=test_dataloader.batch_size, disable=None)\n",
    "    pbar = tqdm(test_dataloader, unit=\" images\", unit_scale=test_dataloader.batch_size)\n",
    "\n",
    "    empty_images_count = 0\n",
    "    for batch in pbar:\n",
    "        \n",
    "        image_ids = batch['image_id']\n",
    "\n",
    "        if args.tta:\n",
    "            flipped_batch = next(flipped_test_dataloader_iter)\n",
    "        else:\n",
    "            flipped_batch = None\n",
    "\n",
    "        probs = predict(args, model, batch, flipped_batch, use_gpu=use_gpu)\n",
    "        \n",
    "        # prediction\n",
    "        pred = probs > args.threshold\n",
    "        \n",
    "        # submission of pred\n",
    "        rle = rlenc_np(pred)\n",
    "        submission.update(dict(zip(image_ids, rle)))\n",
    "\n",
    "        empty_images_count += (pred.sum(axis=(1, 2)) == 0).sum()\n",
    "\n",
    "        # probabilities\n",
    "        probs_uint16 = (65535 * probs).astype(dtype=np.uint16)\n",
    "        prediction.update(dict(zip(image_ids, probs_uint16)))\n",
    "            \n",
    "    empty_images_percentage = empty_images_count / len(prediction)\n",
    "    print(\"empty images: %.2f%% (in public LB 38%%)\" % (100 * empty_images_percentage))\n",
    "\n",
    "    # probabilities\n",
    "    gzip_save('-'.join([args.output_prefix, 'probabilities.pkl.gz']), prediction)\n",
    "    \n",
    "    # submission\n",
    "    sub = pd.DataFrame.from_dict(submission, orient='index')\n",
    "    sub.index.names = ['id']\n",
    "    sub.columns = ['rle_mask']\n",
    "    sub.to_csv('-'.join([args.output_prefix, 'submission.csv']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qc_test(args):\n",
    "    \"\"\" for testing a small dataset \"\"\"\n",
    "\n",
    "    # test dataset\n",
    "    test_transform = Compose([PrepareImageAndMask(),\n",
    "                              ResizeToNxN(img_size) if args.resize else PadToNxN(img_size), HWCtoCHW()])\n",
    "    test_dataset = SaltIdentification(mode='test', transform=test_transform, preload=False)\n",
    "    \n",
    "    # random indices\n",
    "    indices = np.random.choice( len(test_dataset), args.batch_size)\n",
    "    print(f'indices: {indices}')\n",
    "    \n",
    "    # picked test dataset\n",
    "    test_dataset0 = torch.utils.data.Subset(test_dataset, indices)\n",
    "    \n",
    "    test_dataloader = DataLoader(test_dataset0, batch_size=args.batch_size, num_workers=args.dataload_workers_nums)\n",
    "    test_dataloader_iter = iter(test_dataloader)\n",
    "\n",
    "    # flipped test dataset\n",
    "    flipped_test_transform = Compose([PrepareImageAndMask(), HorizontalFlip(),\n",
    "                                      ResizeToNxN(img_size) if args.resize else PadToNxN(img_size), HWCtoCHW()])\n",
    "    flipped_test_dataset = SaltIdentification(mode='test', transform=flipped_test_transform, preload=False)\n",
    "    \n",
    "    # for flipped test dataset\n",
    "    flipped_test_dataset0 = torch.utils.data.Subset(flipped_test_dataset, indices)\n",
    "    \n",
    "    flipped_test_dataloader_iter = iter(DataLoader(flipped_test_dataset0, batch_size=args.batch_size,\n",
    "                                                   num_workers=args.dataload_workers_nums))\n",
    "\n",
    "    model.eval()\n",
    "    torch.set_grad_enabled(False)\n",
    "    \n",
    "    # test data\n",
    "    batch = next(test_dataloader_iter)\n",
    "    \n",
    "    image_ids = batch['image_id']\n",
    "    images = batch['input']\n",
    "\n",
    "    # flipped data\n",
    "    if args.tta:\n",
    "        flipped_batch = next(flipped_test_dataloader_iter)\n",
    "    else:\n",
    "        flipped_batch = None\n",
    "\n",
    "    # predicted probabilities\n",
    "    probs = predict(args, model, batch, flipped_batch, use_gpu=use_gpu)\n",
    "\n",
    "    # prediction\n",
    "    pred = np.zeros_like(probs)\n",
    "    pred[probs > args.threshold] = 1\n",
    "\n",
    "    # output probabilities\n",
    "    probs_uint16 = (65535 * probs).astype(dtype=np.uint16)\n",
    "\n",
    "    # input images\n",
    "    image_samples = images[:, :, y0:y1, x0:x1].permute(0, 2, 3, 1).numpy()\n",
    "        \n",
    "    return image_ids, pred, probs_uint16, image_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description=__doc__, formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "parser.add_argument(\"--batch-size\", type=int, default=30, help='batch size')\n",
    "parser.add_argument(\"--dataload-workers-nums\", type=int, default=8, help='number of workers for dataloader')\n",
    "parser.add_argument('--tta', action='store_true', help='test time augmentation')\n",
    "parser.add_argument('--seed', type=int, default=None, help='manual seed for deterministic')\n",
    "parser.add_argument(\"--threshold\", type=float, default=0.5, help='probability threshold')\n",
    "parser.add_argument(\"--output-prefix\", type=str, default='noprefix', help='prefix string for output files')\n",
    "parser.add_argument('--resize', action='store_true', help='resize to 128x128 instead of reflective padding')\n",
    "parser.add_argument(\"model\", help='a pretrained neural network model')\n",
    "\n",
    "# args examples\n",
    "arg_commands = '--tta my_runs/models/best-metric-model-fold0.pth --output-prefix fold0'\n",
    "args = parser.parse_args(arg_commands.split())\n",
    "print(vars(args))\n",
    "\n",
    "# execute the codes\n",
    "use_gpu = torch.cuda.is_available()\n",
    "print('use_gpu', use_gpu)\n",
    "\n",
    "print(\"loading model...\")\n",
    "model = models.load(args.model)\n",
    "model.float()\n",
    "\n",
    "if use_gpu:\n",
    "    if args.seed is not None:\n",
    "        torch.manual_seed(args.seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "    else:\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "    model.cuda()\n",
    "\n",
    "print(\"testing %s...\" % args.model)\n",
    "start = time.time()\n",
    "# the whole dataset\n",
    "#test(args)\n",
    "# show only a batch\n",
    "image_ids, pred, probs_uint16, image_samples = qc_test(args)\n",
    "time_elapsed = time.time() - start\n",
    "time_str = 'total time elapsed: {:.0f}h {:.0f}m {:.0f}s '.format(time_elapsed // 3600,\n",
    "                                                                 time_elapsed % 3600 // 60,\n",
    "                                                                 time_elapsed % 60)\n",
    "print(time_str)\n",
    "print(\"finished\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred.shape, probs_uint16.shape, image_samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "nrows = pred.shape[0]\n",
    "\n",
    "plt.figure(figsize=(8, 3.5*nrows))\n",
    "\n",
    "for i in range(nrows):\n",
    "    # overlay two images\n",
    "    plt.subplot(nrows, 3, i*3+1)\n",
    "    plt.imshow(pred[i])\n",
    "    # \n",
    "    plt.axis('off')\n",
    "    #\n",
    "    plt.subplot(nrows, 3, i*3+2)\n",
    "    plt.imshow(image_samples[i], cmap='Greys')\n",
    "    # \n",
    "    plt.axis('off')\n",
    "    #\n",
    "    plt.subplot(nrows, 3, i*3+3)\n",
    "    plt.imshow(pred[i])\n",
    "    plt.imshow(image_samples[i], alpha=0.4, cmap='Greys')\n",
    "    # \n",
    "    plt.axis('off')\n",
    "\n",
    "# plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.8, bottom=0.0, \n",
    "                    left=0.0, right=1.0, \n",
    "                    hspace=0.05, wspace=0.05)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
